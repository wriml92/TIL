## GoogLeNet

&emsp;GoogLeNet은 2014년 Google의 연구팀이 개발한 CNN(Convolutional Neural Network) 아키텍처로, ImageNet Large Scale Visual Recognition Challenge(ILSVRC) 2014에서 우승하며 큰 주목을 받았습니다. GoogLeNet은 "Inception" 아키텍처를 중심으로 설계되었으며, 네트워크 깊이를 확장하는 동시에 계산 효율성을 높이는 혁신적인 구조를 도입했습니다. 이 모델은 특히 여러 크기의 필터를 병렬로 적용하는 방식으로, 다양한 크기의 특징을 동시에 추출할 수 있는 Inception 모듈을 활용하여 설계되었습니다.

&emsp;GoogLeNet은 효율성과 성능을 극대화하는 동시에, 더 깊고 넓은 모델 구조로 CNN 아키텍처를 한 단계 발전시켰습니다.

### GoogLeNet의 주요 특징

1. **Inception 모듈**  
   &emsp;GoogLeNet의 핵심 구성 요소는 Inception 모듈입니다. Inception 모듈은 여러 크기의 필터(1x1, 3x3, 5x5)와 풀링(3x3 Max Pooling)을 병렬로 적용하여 다양한 크기의 특성을 동시에 추출합니다. 이러한 설계는 네트워크가 이미지 내에서 여러 크기의 특징을 포착하는 데 효과적입니다.

   - **1x1 컨볼루션**: 차원 축소를 통해 계산 비용을 줄이며, 모델이 깊어지는 것을 가능하게 만듭니다.
   - **3x3 및 5x5 컨볼루션**: 다른 크기의 필터를 사용하여 다양한 스케일의 특징을 추출합니다.
   - **3x3 Max Pooling**: 다운샘플링을 통해 중요한 특징을 강조합니다.
   - **결합**: 각 필터의 출력을 결합하여 다음 계층으로 전달하므로 네트워크가 보다 풍부한 정보를 학습할 수 있습니다.

2. **차원 축소**  
   &emsp;Inception 모듈 내에서 1x1 컨볼루션을 먼저 수행하여 차원을 줄이는 방식을 사용합니다. 이를 통해 네트워크의 계산 효율을 극대화할 수 있으며, 많은 계층을 쌓아도 연산 비용을 제한할 수 있게 됩니다. 이 차원 축소 덕분에 GoogLeNet은 깊은 네트워크이지만 상대적으로 적은 파라미터로도 높은 성능을 발휘할 수 있습니다.

3. **22 계층의 깊은 구조**  
   &emsp;GoogLeNet은 총 22개의 계층을 가지며, 이로 인해 깊은 신경망의 성능을 발휘할 수 있습니다. 그러나 이 네트워크는 Inception 모듈과 1x1 컨볼루션을 통해 연산량을 줄이고, 과도한 파라미터 수를 억제하여 효율성을 높였습니다. 이러한 깊은 구조는 GoogLeNet이 이미지 분류 성능을 높이는 데 기여했습니다.

4. **보조 분류기(Auxiliary Classifier)**  
   &emsp;GoogLeNet은 네트워크 중간에 보조 분류기를 배치하여 학습 중에 도움을 주는 역할을 합니다. 보조 분류기는 중간 계층에서 나오는 특징을 통해 별도의 분류 작업을 수행하는데, 이는 네트워크의 깊이가 깊어지며 발생할 수 있는 그래디언트 소실 문제를 완화하는 데 도움을 줍니다. 또한 보조 분류기를 통해 네트워크가 학습 초기에 더 빠르게 수렴하도록 유도할 수 있습니다.

5. **효율적인 파라미터 수**  
   &emsp;GoogLeNet은 22층으로 구성된 깊은 네트워크임에도 불구하고, 약 500만 개의 파라미터를 갖고 있습니다. 이는 VGGNet(약 1억 3천 8백만 개)과 비교하면 매우 효율적입니다. GoogLeNet의 파라미터 수가 적다는 것은 메모리 효율성이 높고, 더 적은 연산 비용으로도 좋은 성능을 낼 수 있다는 것을 의미합니다.

### GoogLeNet의 구조

GoogLeNet의 기본 구조는 Inception 모듈을 여러 번 쌓아올려 설계되었습니다. 주요 구조는 다음과 같습니다:

   1. **입력 계층**: 224 X 224 크기의 이미지를 입력으로 받습니다.
   2. **기본 컨볼루션 및 풀링 층**: 초반에 두 개의 컨볼루션 층과 풀링 층을 통해 기본 특징을 추출합니다.
   3. **Inception 모듈 스택**: 네트워크의 대부분을 차지하며, 여러 개의 Inception 모듈이 연속적으로 쌓여 있습니다.
   4. **보조 분류기**: 네트워크 중간에 위치하여 그래디언트 소실 문제를 완화하며 학습을 돕습니다.
   5. **완전 연결 층 대신 글로벌 평균 풀링(Global Average Pooling)**  
      GoogLeNet은 마지막 부분에서 완전 연결 층 대신 Global Average Pooling을 사용합니다. 이는 각 특징 맵의 평균을 계산하여 소프트맥스 층으로 전달하는 방식으로, 파라미터 수를 줄이고 과적합을 방지하는 데 도움을 줍니다.

### GoogLeNet의 성능 및 영향

&emsp;GoogLeNet은 ILSVRC 2014에서 우승하며 딥러닝 분야에 큰 영향을 미쳤습니다. 이 모델은 깊고 복잡한 구조의 CNN에서도 효율성을 유지할 수 있다는 가능성을 보여줬고, 이후 다양한 변형 모델들이 등장하게 되었습니다. GoogLeNet의 인셉션 모듈은 딥러닝 모델의 효율성을 높이는 기법으로 자리 잡았고, 후속 연구에서 이 모듈을 개선한 Inception v2, v3, v4 등의 모델이 개발되었습니다.

&emsp;GoogLeNet은 복잡한 네트워크 구조와 차원 축소 기법을 통해 높은 성능을 유지하면서도 효율적인 계산을 가능하게 했다는 점에서 딥러닝 모델의 발전에 중요한 기여를 했습니다.