## AlexNet

&emsp;AlexNet은 2012년 ILSVRC(Imagenet Large Scale Visual Recognition Challenge)에서 높은 성능으로 이미지 분류 대회에서 우승하며 딥러닝, 특히 CNN(Convolutional Neural Network)의 가능성을 알린 모델입니다. 이 모델은 알렉스 크리제브스키(Alex Krizhevsky), 일리아 수츠케버(Ilya Sutskever), 그리고 제프리 힌튼(Geoffrey Hinton)이 개발하였으며, 그 당시 GPU를 사용해 학습시킨 최초의 딥러닝 모델 중 하나입니다. AlexNet은 딥러닝이 이미지 처리 분야에서 강력한 성능을 발휘할 수 있음을 증명했습니다.

### AlexNet의 주요 특징
&emsp;AlexNet의 구조와 혁신적인 특징은 다음과 같습니다:

1. **8개의 계층(레이어)**  
   &emsp;AlexNet은 총 8개의 학습 가능한 계층으로 구성됩니다. 그 중 5개는 컨볼루션 층이며, 나머지 3개는 완전 연결(Fully Connected) 층입니다.
   - **컨볼루션 층**: 5개의 컨볼루션 층이 연속적으로 입력 이미지를 처리하면서 점진적으로 고차원의 특징을 추출합니다.
   - **완전 연결 층**: 마지막 부분에는 3개의 완전 연결 층이 있어 최종적으로 이미지 분류를 수행합니다.

2. **ReLU 활성화 함수**  
   &emsp;AlexNet은 활성화 함수로 ReLU(Rectified Linear Unit)를 사용하여 비선형성을 도입하고, 시그모이드나 하이퍼볼릭 탄젠트 함수에 비해 학습 속도를 크게 향상시켰습니다. 이로 인해 네트워크는 더 빠르게 수렴할 수 있었으며, 이 아이디어는 이후 많은 딥러닝 모델에서 채택되었습니다.

3. **드롭아웃(Dropout) 기법 도입**  
   &emsp;AlexNet은 과적합(overfitting)을 방지하기 위해 드롭아웃을 사용했습니다. 드롭아웃은 학습 시 특정 뉴런을 무작위로 비활성화하여 네트워크가 학습 데이터에 과도하게 맞추는 현상을 방지하는 정규화 기법입니다. 이는 모델의 일반화 성능을 높이는 데 기여했습니다.

4. **데이터 증대(Data Augmentation)**  
   &emsp;AlexNet은 더 많은 데이터로 학습할 수 있도록, 회전, 자르기, 색상 변화 등의 데이터 증대 기법을 사용했습니다. 이는 모델이 데이터의 다양한 변형에도 잘 대응할 수 있도록 했으며, 더 나은 일반화 성능을 얻는 데 도움을 주었습니다.

5. **LRN(Local Response Normalization)**  
   &emsp;AlexNet에서는 LRN이라는 정규화 기법을 사용하여 ReLU가 활성화된 뉴런들의 출력을 정규화하고, 인접한 뉴런들과의 경쟁을 유도했습니다. 이 기법은 후속 모델에서는 자주 사용되지 않지만, 당시 성능을 높이는 데 중요한 역할을 했습니다.

6. **GPU 병렬 학습**  
   &emsp;AlexNet은 당시 GPU 병렬 학습을 적극 활용한 모델로, 두 개의 GPU를 사용하여 모델을 병렬로 학습했습니다. 당시 CNN 학습에서 GPU를 효과적으로 사용하는 것이 흔치 않았기 때문에, AlexNet은 이를 통해 큰 모델을 효율적으로 학습시킬 수 있었습니다.

### AlexNet의 구조
&emsp;AlexNet의 구조는 다음과 같습니다:

   1. **입력 계층**: \(227 \times 227\) 크기의 이미지 입력.
   2. **컨볼루션 및 풀링 계층**: 
      - 첫 번째 컨볼루션 층에서 \(11 \times 11\) 필터와 큰 스트라이드를 사용하여 특징 추출.
      - 이후의 컨볼루션 층은 \(5 \times 5\) 및 \(3 \times 3\) 필터를 사용.
      - 일부 계층에서는 최대 풀링(Max Pooling)을 적용해 특성을 추출하며, 크기를 축소.
   3. **완전 연결 계층**: 4096개의 유닛을 가진 두 개의 완전 연결 계층을 거쳐 마지막 소프트맥스 층에서 이미지 분류.

### AlexNet의 영향
&emsp;AlexNet은 딥러닝이 본격적으로 이미지 처리 및 컴퓨터 비전 분야에서 주목받는 계기를 마련했습니다. 이 모델은 단순히 기술적으로 좋은 성능을 낸 것에 그치지 않고, GPU의 병렬 처리와 드롭아웃, ReLU 같은 새로운 개념을 효과적으로 조합하여 딥러닝 연구에 큰 기여를 했습니다. AlexNet의 성과는 딥러닝 모델 개발의 활발한 발전을 이끌었으며, 후속 모델인 VGGNet, GoogLeNet, ResNet 등의 기초가 되었습니다.