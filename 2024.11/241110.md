# VGGNet

VGGNet은 옥스퍼드 대학교의 Visual Geometry Group(VGG)에서 개발한 딥러닝 모델로, 특히 이미지 분류 분야에서 유명한 CNN(Convolutional Neural Network) 아키텍처 중 하나입니다. VGGNet은 2014년 ILSVRC(이미지넷 대회)에서 좋은 성적을 거두며 주목을 받았습니다. VGGNet의 주요 목표는 단순하면서도 효과적인 구조로 깊은 신경망을 설계하여 이미지 분류 성능을 높이는 것이었습니다.

VGGNet의 구조와 특성은 다음과 같습니다:

### 1. **단순한 아키텍처**
   VGGNet의 핵심 아이디어는 작은 \(3 \times 3\) 크기의 필터를 여러 층에 걸쳐 사용하여 깊은 신경망을 구성하는 것입니다. 이전의 CNN 모델들이 \(5 \times 5\) 또는 \(7 \times 7\) 등의 큰 필터를 사용하는 경우가 많았던 것에 반해, VGGNet은 \(3 \times 3\) 필터를 쌓아 깊이를 더하면서도 계산 복잡도를 줄이는 방식으로 설계되었습니다. 이러한 작은 필터의 연속 사용은 모델의 표현력을 높이는 데 기여합니다.

### 2. **VGGNet의 구성 (VGG-16과 VGG-19)**
   VGGNet에는 여러 가지 버전이 있지만, 대표적으로 **VGG-16**과 **VGG-19**가 있습니다. 숫자는 각 모델의 계층 수를 의미합니다. 예를 들어, VGG-16은 16개의 가중치 계층(컨볼루션 층과 완전 연결 층 포함)으로 구성됩니다.
   
   - **VGG-16**: 13개의 컨볼루션 층과 3개의 완전 연결 층으로 구성됨.
   - **VGG-19**: 16개의 컨볼루션 층과 3개의 완전 연결 층으로 구성됨.
   
   VGGNet의 구조는 보통 다음과 같은 형태를 따릅니다: 여러 개의 컨볼루션 층 → 풀링 층(Max Pooling) → 컨볼루션 층 반복 → 완전 연결 층(Fully Connected Layer) → 소프트맥스(Softmax) 출력.

### 3. **계층 별 세부 구성**
   - **컨볼루션 층**: VGGNet은 \(3 \times 3\) 컨볼루션 필터를 사용하여 같은 크기의 패딩(Same Padding)을 적용합니다. 이러한 패딩은 입력과 출력의 크기를 동일하게 유지하면서 특징을 추출합니다.
   - **풀링 층**: VGGNet은 주로 \(2 \times 2\) 크기의 Max Pooling을 사용하여 공간 차원을 절반으로 줄입니다.
   - **완전 연결 층**: 네트워크의 마지막 부분에서, 4096개의 유닛을 가진 완전 연결 층이 2개, 그리고 최종 출력층이 이어집니다.
   - **ReLU 활성화 함수**: 각 층에서는 ReLU(Rectified Linear Unit)를 활성화 함수로 사용하여 비선형성을 추가합니다.

### 4. **모델의 장점과 단점**
   - **장점**: 깊은 층을 쌓아가며 더 복잡하고 추상적인 특징을 추출할 수 있고, 상대적으로 단순한 구조를 유지하며 고성능을 발휘합니다.
   - **단점**: 많은 층으로 인해 파라미터 수가 많아지고 연산량이 증가하여 학습 및 추론 속도가 느리고, 메모리 사용량도 큽니다. 특히, VGGNet은 훈련과 추론에 높은 GPU 메모리를 요구합니다.

### 5. **VGGNet의 영향과 활용**
   VGGNet은 이후 개발된 ResNet, DenseNet 등 더 복잡하고 효율적인 CNN 아키텍처에 영감을 주었습니다. 비록 VGGNet 자체는 현재의 최신 모델에 비해 비효율적이지만, 모델 아키텍처 연구의 중요한 기준이 되었으며, 전이 학습(Transfer Learning)에도 자주 사용되는 모델로 자리 잡았습니다.

VGGNet은 직관적이면서도 성능이 뛰어난 CNN 모델로서, 딥러닝 분야의 발전에 큰 기여를 한 모델로 평가받고 있습니다.