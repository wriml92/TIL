&emsp;오늘은 개인과제 마지막 부분 단계인 8번째 단계에서 10번째 단계를 실행해보고자 합니다.   

---

# 8. 프롬프트 템플릿 정의   
&emsp;이 코드는 LangChain에서 ChatPromptTemplate을 사용해 대화형 프롬프트 템플릿을 정의하는 작업입니다.   
&emsp;주어진 문맥(context)에 기반하여 사용자의 질문에 답변하도록 시스템의 작동 방식을 설계합니다.   
```python
# 프롬프트 템플릿 정의
contextual_prompt = ChatPromptTemplate.from_messages([
    ("system", "Answer the question using only the following context."),
    ("user", "Context: {context}\\n\\nQuestion: {question}")
])
```   
- 이 코드는 LangChain의 `ChatPromptTemplate`을 사용해 문맥 기반 질의응답 프롬프트를 정의합니다.   
- `system` 메시지로 모델 행동 지침을 설정하고, `user` 메시지에서 동적 변수를 사용해 구체적인 입력 템플릿을 만듭니다.   
- 실제 실행 시 `{context}`와 `{question}`에 데이터를 채워 넣고, 이를 통해 질문에 답변할 수 있습니다.   
- 주로 제한된 문맥에서 정보 제공이 필요한 응용 프로그램에서 사용됩니다.   

# 9. RAG 체인 구성
&emsp;이 코드는 **RAG (Retrieval-Augmented Generation)** 프로세스를 구현하기 위해 세 가지 주요 컴포넌트를 정의하고 이를 체인으로 조합하여 사용자의 질문에 대한 답변을 생성하는 방법을 보여줍니다. 아래에서 각 클래스와 구성 요소에 대해 상세히 설명하겠습니다.   
```python
class SimplePassThrough:
    def invoke(self, inputs, **kwargs):
        return inputs

class ContextToPrompt:
    def __init__(self, prompt_template):
        self.prompt_template = prompt_template
    
    def invoke(self, inputs):
        # 문서 내용을 텍스트로 변환
        if isinstance(inputs, list):
            context_text = "\n".join([doc.page_content for doc in inputs])
        else:
            context_text = inputs

        # 문서 내용을 텍스트로 변환
        formatted_prompt = self.prompt_template.format_messages(
            context=context_text,
            question=inputs.get("question", "")
        )
        return formatted_prompt

# Retriever를 invoke() 메서드로 래핑하는 클래스 정의
class RetrieverWrapper:
    def __init__(self, retriever):
        self.retriever = retriever

    def invoke(self, inputs):
        if isinstance(inputs, dict):
            query = inputs.get("question", "")
        else:
            query = inputs
        # 검색 수행
        response_docs = self.retriever.get_relevant_documents(query)
        return response_docs

llm_chain = LLMChain(llm=model, prompt=contextual_prompt)

# RAG 체인 설정
rag_chain_debug = {
    "context": RetrieverWrapper(retriever),
    "prompt": ContextToPrompt(contextual_prompt),
    "llm": model
}
```   
이 코드는 RAG 체인을 구성하기 위해 각 단계별로 클래스를 정의하고 이를 조합했습니다:   
- `RetrieverWrapper`: 문서 검색 담당.
- `ContextToPrompt`: 검색된 문서를 기반으로 프롬프트 생성.
- `LLMChain`: 프롬프트를 기반으로 LLM 응답 생성. 전체 체인은 문서 검색부터 답변 생성까지의 RAG 프로세스를 자동화하여 효율적으로 작동하도록 설계되었습니다.   

# 10. 챗봇 구동 확인
&emsp;이 코드는 질의응답 루프를 구현합니다. 사용자는 반복적으로 질문을 입력할 수 있으며, 시스템은 RAG 체인을 통해 관련 문서를 검색하고 답변을 생성하여 출력합니다. 아래에서 각 부분을 상세히 설명합니다.   
```python
# 챗봇 구동
while True:
    print("========================")
    query = input("질문을 입력하세요 : ")
    
    if query.lower() in ["종료", "quit"]: # 종료하고 싶을 경우
        print("프롬프트를 종료합니다.")
        break

    # 1. Retriever로 관련 문서 검색
    response_docs = rag_chain_debug["context"].invoke({"question": query})

    # 2. 문서를 프롬프트로 변환
    prompt_messages = rag_chain_debug["prompt"].invoke({
        "context": response_docs,
        "question": query
    })

    # 3. LLM으로 응답 생성
    response = rag_chain_debug["llm"].invoke(prompt_messages)
    
    print("\n답변:")
    print(response.content)
```   
1. **사용자 입력**: 사용자가 질문을 입력하면 `query`에 저장됩니다.
2. **문서 검색**: `RetrieverWrapper`를 사용해 입력 질문과 관련된 문서를 검색하고 `response_docs`를 반환합니다.
3. **프롬프트 생성**: 검색된 문서와 질문을 기반으로 프롬프트 템플릿을 채우고 `prompt_messages`를 생성합니다.
4. **답변 생성**: GPT-4 모델에 프롬프트를 전달하여 답변을 생성하고 `response.content`에 저장합니다.
5. **결과 출력**: 생성된 답변을 사용자에게 출력합니다.
6. **루프 반복**: 새로운 질문을 입력받아 위 과정을 반복합니다.   

---

&emsp;오늘로써 개인과제는 완료하였다. 내일부터 팀프로젝트가 시작되어서 준비를 잘 해야겠다.