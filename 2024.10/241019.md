#### 인공 신경망
- 생물학적 뉴런의 원리에 착안한 것
- 이를 그대로 구현하기 보다는 유사한 계산 원리로 동작하도록 설계
- 뉴런은 전달되는 신호의 가중 합을 구한 후 활성함수를 거쳐 출력을 만들어 내는 단순한 처리를 수행
- 이때 활성함수는 뉴런의 출력이 입력에 따라 활성화될 수 있도록 하는 역할을 하는 비선형 함수를 사용
- 입력이 뉴런에 전달되는 가중치는 학습 과정을 통하여 결정

#### 활성함수
* **단위 계단 함수** : 입력의 부호에 따라 0 또는 1을 출력하며, 따라서 입력이 0인 지점에서 불연속이며 미분 구하기 불가능
* **시그모이드** : 'S'자 형태의 곡선이며 0부터 1 또는 -1부터 1 사이의 값을 갖는, 전 구간에서 미분 가능한 함수
* **ReLU** : 입력 u에 대해 max(u, 0)을 출력하는 함수
* **GeLU** : 전 구간에서 미분 가능하도록 한 ReLU의 변형

#### 다층 퍼셉트론(MLP)
- 피드포워드 신경망 구조
- 역전파 알고리즘을 이용하여 학습
- 학습 데이터 집합은 입력 데이터와 출력층의 레이블로 구성
- 단층 퍼셉트론은 선형 경계로 표현될 수 있는 문제만 해결 가능
- 층 수가 증가할수록 고차원적인 특징을 표현할 수 있어 복잡한 결정경계에 대해 학습 가능
- 일반적으로 은닉층의 활성함수는 비선형 함수를 사용
- 선형 함수를 사용할 경우 그 은닉층이 없이도 동등한 출력을 낼 수 있는 망으로 표현 가능
- 층을 추가하여 얻을 수 있는 표현력의 개선 효과 없음.

#### 역전파 알고리즘
* 단위 계단 함수는 입력이 0인 경우 미분을 구할 수 없음.
* 그 외의 경우에는 미분이 0이어서 경사 하강법 적용이 불가
* 학습 데이터의 레이블은 출력층에 대한 것만 제공
* 학습은 출력층에서 입력층 방향으로 역방향 진행
* 체인 룰에 따라 각 층의 연결 가중치에 대한 손실함수의 편미분 구함.
* 이를 적절히 정한 학습률에 따라 반영하여 그 가중치를 업데이트

#### 역전파 알고리즘에서 모멘텀의 용도
- 모멘텀은 이전 단계의 가중치 변화량을 모멘텀 m의 비율로 반영해 현 단계의 가중치 변화량을 정함.
- 연결 가중치의 변화가 과거 변화의 경향을 유지함으로써 변화의 방향이 급격히 변화하는 것을 완화
- 기본적인 경사 하강법의 성능을 개선이 가능